{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iovcharenko/Documents/NotWork/UCU/liner-algebra/ucu-linear-algebra-final-project\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.data import get_netflix_dataframe\n",
    "from src.data import combine_dataframes\n",
    "from src.data import generate_sparce_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24058263/24058263 [00:14<00:00, 1673642.25it/s]\n"
     ]
    }
   ],
   "source": [
    "df = get_netflix_dataframe(\"data/combined_data_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process folder: data/subsets/hight-sparsity\n",
      "shape:  (1000,) (1000,)\n",
      "sparsity: 0.957375\n",
      "process folder: data/subsets/mid-sparsity\n",
      "shape:  (1000,) (1000,)\n",
      "sparsity: 0.905062\n",
      "process folder: data/subsets/low-sparsity\n",
      "shape:  (1000,) (1000,)\n",
      "sparsity: 0.855243\n"
     ]
    }
   ],
   "source": [
    "subsets_folder = data_folder / \"subsets\"\n",
    "\n",
    "subsets = [\n",
    "    (subsets_folder / \"high-sparsity\", (0.50, 0.80)), # 0.957 sparsity \n",
    "    (subsets_folder / \"mid-sparsity\", (0.80, 0.90)),   # 0.901 sparsity\n",
    "    (subsets_folder / \"low-sparsity\", (0.90, 0.95)),   # 0.850 sparsity\n",
    "]\n",
    "\n",
    "customer_amount = 1000\n",
    "movie_amount = 1000\n",
    "\n",
    "for (folder_name, q) in subsets:\n",
    "    print(f\"process folder: {folder_name}\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    folder_name.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    user_rates = df.groupby(\"customer_id\").size()\n",
    "\n",
    "    lower_q = np.quantile(user_rates.values, q[0])\n",
    "    upper_q = np.quantile(user_rates.values, q[1])\n",
    "\n",
    "    user_rates = user_rates[user_rates.values >= lower_q]\n",
    "    user_rates = user_rates[user_rates.values <= upper_q]\n",
    "\n",
    "    selected_customer_ids = np.random.choice(\n",
    "        user_rates.index.values, \n",
    "        customer_amount, replace=False,\n",
    "    )\n",
    "\n",
    "    small_df = df[df.customer_id.isin(selected_customer_ids)]\n",
    "    selected_movie_ids = small_df.groupby(\"movie_id\") \\\n",
    "                        .size().sort_values(ascending=False)[:movie_amount].index.values\n",
    "\n",
    "    small_df = small_df[small_df.movie_id.isin(selected_movie_ids)]\n",
    "\n",
    "    \n",
    "    customer_ids = small_df.customer_id.sort_values().unique().tolist()\n",
    "    small_df.customer_id = small_df.customer_id.apply(lambda i: customer_ids.index(i))\n",
    "\n",
    "    movie_ids = small_df.movie_id.sort_values().unique().tolist()\n",
    "    small_df.movie_id = small_df.movie_id.apply(lambda i: movie_ids.index(i))\n",
    "\n",
    "    \n",
    "    small_df.date = pd.to_datetime(small_df.date)\n",
    "    small_df = small_df.sort_values(\"date\")\n",
    "\n",
    "    small_df = small_df.copy()\n",
    "    small_df = small_df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    tr_idx, val_idx = train_test_split(\n",
    "        small_df.index, \n",
    "        test_size=0.2,\n",
    "        shuffle=True, \n",
    "        random_state=42,\n",
    "        stratify=small_df.customer_id\n",
    "    )\n",
    "    small_df.loc[tr_idx, \"split\"] = \"train\"\n",
    "    small_df.loc[val_idx, \"split\"] = \"val\"\n",
    "    \n",
    "    print(\n",
    "        \"shape: \",\n",
    "        small_df.customer_id.unique().shape, \n",
    "        small_df.movie_id.unique().shape\n",
    "    )\n",
    "\n",
    "    sparse_m = csr_matrix((\n",
    "        small_df.rating.values, \n",
    "        (small_df.customer_id.values, small_df.movie_id.values)\n",
    "    ))\n",
    "\n",
    "    dense_m = sparse_m.todense()\n",
    "    sparsity = (dense_m == 0).sum() / dense_m.size\n",
    "    print(f\"sparsity: {sparsity}\")\n",
    "    \n",
    "    \n",
    "    small_df.to_csv(folder_name / \"records.csv\", index=False)\n",
    "    \n",
    "    pd.DataFrame({\n",
    "        \"subset_id\": range(0, len(movie_ids)),\n",
    "        \"netflix_id\": movie_ids,\n",
    "    }).to_csv(folder_name / \"movies.csv\", index=False)\n",
    "\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"subset_id\": range(0, len(customer_ids)),\n",
    "        \"netflix_id\": customer_ids,\n",
    "    }).to_csv(folder_name / \"custormers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def custom_train_test_split(df, test_size=0.2):\n",
    "    np.random.seed(42)\n",
    "    df = df.copy()\n",
    "    df = df.sample(frac=1)\n",
    "\n",
    "    m_count = {m: 0 for m in df.movie_id.unique()}\n",
    "    c_count = {c: 0 for c in df.customer_id.unique()}\n",
    "\n",
    "    test_df = pd.DataFrame()\n",
    "    items_size = len(df)\n",
    "    m_skipped = False\n",
    "    c_skipped = False\n",
    "\n",
    "    while len(test_df) / items_size < test_size:\n",
    "        m_items = list(m_count.items())\n",
    "        random.shuffle(m_items)\n",
    "        m_count = list(sorted(m_items, key=lambda x: x[1]))\n",
    "        m_id = m_count[0][0]\n",
    "        m_count = dict(m_count)\n",
    "\n",
    "        m_rows_idx = df[df.movie_id == m_id].index\n",
    "        if not m_rows_idx.empty:\n",
    "            m_count[m_id] += 1\n",
    "            m_selected = df.loc[m_rows_idx] \\\n",
    "                           .sort_values(\"customer_id\", key=lambda c: c.map(c_count)).index[0]\n",
    "#             m_selected = np.random.choice(m_rows_idx)\n",
    "            c_count[df.loc[m_selected].customer_id] += 1\n",
    "            test_df = test_df.append(df.loc[m_selected])\n",
    "            df = df.drop(index=m_selected)\n",
    "        else:\n",
    "            m_skipped = True\n",
    "            print(\"skip movie select\")\n",
    "\n",
    "        c_items = list(c_count.items())\n",
    "        random.shuffle(c_items)\n",
    "        c_count = list(sorted(c_items, key=lambda x: x[1]))\n",
    "        c_id = c_count[0][0]\n",
    "        c_count = dict(c_count)\n",
    "        c_rows_idx = df[df.customer_id == c_id].index\n",
    "        if not c_rows_idx.empty:\n",
    "            c_count[c_id] += 1\n",
    "            c_selected = df.loc[c_rows_idx] \\\n",
    "                           .sort_values(\"movie_id\", key=lambda m: m.map(m_count)).index[0]\n",
    "#             c_selected = np.random.choice(c_rows_idx)\n",
    "            m_count[df.loc[c_selected].movie_id] += 1\n",
    "            test_df = test_df.append(df.loc[c_selected])\n",
    "            df = df.drop(index=c_selected)\n",
    "        else:\n",
    "            c_skipped = True\n",
    "            print(\"skip customer select\")\n",
    "\n",
    "        if m_skipped and c_skipped:\n",
    "            print(\"break, all skipped\")\n",
    "            break\n",
    "\n",
    "        print(\"fraction: \", len(test_df) / items_size)\n",
    "        \n",
    "    return df.index, test_df.index, len(test_df) / items_size\n",
    "\n",
    "tr_idx, val_idx, frac = custom_train_test_split(small_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.loc[tr_idx, \"split\"] = \"train\"\n",
    "small_df.loc[val_idx, \"split\"] = \"val\"\n",
    "\n",
    "\n",
    "print(len(set(small_df[small_df.split == \"train\"].customer_id)))\n",
    "print(len(set(small_df[small_df.split == \"val\"].customer_id)))\n",
    "\n",
    "print(len(set(small_df[small_df.split == \"train\"].movie_id)))\n",
    "print(len(set(small_df[small_df.split == \"val\"].movie_id)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
